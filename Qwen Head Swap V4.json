{
  "3": {
    "inputs": {
      "seed": [
        "492",
        0
      ],
      "steps": 4,
      "cfg": 1,
      "sampler_name": "ddim",
      "scheduler": "bong_tangent",
      "denoise": 1,
      "model": [
        "75",
        0
      ],
      "positive": [
        "459",
        0
      ],
      "negative": [
        "460",
        0
      ],
      "latent_image": [
        "88",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "38": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "39": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "66": {
    "inputs": {
      "shift": 1,
      "model": [
        "455",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "75": {
    "inputs": {
      "strength": 1,
      "model": [
        "66",
        0
      ]
    },
    "class_type": "CFGNorm",
    "_meta": {
      "title": "CFGNorm"
    }
  },
  "88": {
    "inputs": {
      "pixels": [
        "485",
        1
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "111": {
    "inputs": {
      "prompt": "head_swap: start with Picture 1 as the base image, keeping its lighting, environment, and background. remove the head from Picture 1 completely and replace it with the head from Picture 2, strictly preserving the hair, eye color, and nose structure of Picture 2. copy the eye direction, head rotation, lighting, and micro-expressions from Picture 1. high quality, sharp details, 4k, digital illustration. The girl is frightened and she is looking slightly downward",
      "clip": [
        "38",
        0
      ],
      "vae": [
        "39",
        0
      ],
      "image1": [
        "485",
        1
      ],
      "image2": [
        "437",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus"
    }
  },
  "435": {
    "inputs": {
      "image": "Memi_Panel_06_v003_CloseUp.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Reference Face"
    }
  },
  "437": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "upscale_method": "lanczos",
      "keep_proportion": "resize",
      "pad_color": "0, 0, 0",
      "crop_position": "center",
      "divisible_by": 2,
      "device": "cpu",
      "image": [
        "491",
        0
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "Resize Image v2"
    }
  },
  "438": {
    "inputs": {
      "conditioning": [
        "111",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "455": {
    "inputs": {
      "lora_name": "Qwen/Edit/bfs_head_v5_2511_merged_version_rank_16_fp16.safetensors",
      "strength_model": 1,
      "model": [
        "462",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "459": {
    "inputs": {
      "reference_latents_method": "index_timestep_zero",
      "conditioning": [
        "111",
        0
      ]
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "Edit Model Reference Method"
    }
  },
  "460": {
    "inputs": {
      "reference_latents_method": "index_timestep_zero",
      "conditioning": [
        "438",
        0
      ]
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "Edit Model Reference Method"
    }
  },
  "462": {
    "inputs": {
      "unet_name": "Qwen/qwen_image_edit_2511_fp8_e4m3fn_scaled_lightning_comfyui.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "478": {
    "inputs": {
      "images": [
        "485",
        1
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "481": {
    "inputs": {
      "image": "ComfyUI_00034_.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Reference Face"
    }
  },
  "482": {
    "inputs": {
      "rgthree_comparer": {
        "images": [
          {
            "name": "A",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_qrsni_00001_.png&type=temp&subfolder=&rand=0.735048124482298"
          },
          {
            "name": "B",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_qrsni_00002_.png&type=temp&subfolder=&rand=0.9180524959002963"
          }
        ]
      },
      "image_a": [
        "484",
        0
      ],
      "image_b": [
        "490",
        0
      ]
    },
    "class_type": "Image Comparer (rgthree)",
    "_meta": {
      "title": "Image Comparer (rgthree)"
    }
  },
  "484": {
    "inputs": {
      "stitcher": [
        "485",
        0
      ],
      "inpainted_image": [
        "8",
        0
      ]
    },
    "class_type": "InpaintStitchImproved",
    "_meta": {
      "title": "✂️ Inpaint Stitch"
    }
  },
  "485": {
    "inputs": {
      "downscale_algorithm": "lanczos",
      "upscale_algorithm": "lanczos",
      "preresize": false,
      "preresize_mode": "ensure minimum and maximum resolution",
      "preresize_min_width": 1024,
      "preresize_min_height": 1024,
      "preresize_max_width": 16384,
      "preresize_max_height": 16384,
      "mask_fill_holes": false,
      "mask_expand_pixels": 0,
      "mask_invert": false,
      "mask_blend_pixels": 32,
      "mask_hipass_filter": 0.1,
      "extend_for_outpainting": false,
      "extend_up_factor": 1,
      "extend_down_factor": 1,
      "extend_left_factor": 1,
      "extend_right_factor": 1,
      "context_from_mask_extend_factor": 1,
      "output_resize_to_target_size": true,
      "output_target_width": 1024,
      "output_target_height": 1024,
      "output_padding": "32",
      "device_mode": "gpu (much faster)",
      "image": [
        "490",
        0
      ],
      "mask": [
        "490",
        1
      ]
    },
    "class_type": "InpaintCropImproved",
    "_meta": {
      "title": "✂️ Inpaint Crop"
    }
  },
  "490": {
    "inputs": {
      "image": "Shot_0050_Close_00001_.png [output]",
      "refresh": "refresh"
    },
    "class_type": "LoadImageOutput",
    "_meta": {
      "title": "Load Image (from Outputs)"
    }
  },
  "491": {
    "inputs": {
      "switch": true,
      "on_false": [
        "435",
        0
      ],
      "on_true": [
        "481",
        0
      ]
    },
    "class_type": "ComfySwitchNode",
    "_meta": {
      "title": "False = Boy, True = Girl"
    }
  },
  "492": {
    "inputs": {
      "seed": 946022816543399
    },
    "class_type": "Seed (rgthree)",
    "_meta": {
      "title": "Seed (rgthree)"
    }
  },
  "499": {
    "inputs": {
      "filename_prefix": "Shot_0050",
      "images": [
        "484",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  }
}